Rossmann Store Sales PredictionüöÄ Project OverviewThis project provides a robust Machine Learning solution to forecast the daily sales of 1,115 Rossmann drug stores across Europe. The main goal is to deliver accurate sales predictions for the immediate next week and up to six weeks ahead, enabling management to make strategic decisions regarding inventory, promotions, and logistics.üéØ Business ObjectiveTo accurately predict the daily sales for each store for a future period.üìä Performance MetricThe model's performance was primarily evaluated using the Mean Absolute Percentage Error (MAPE)1. This metric is highly suitable for sales forecasting problems as it provides the average percentage error of the prediction relative to the actual value, which is easily interpretable for business stakeholders2.‚öôÔ∏è Solution ArchitectureThe project follows a standard Data Science lifecycle, structured into distinct steps:STEP 01: Data DescriptionData Loading (train.csv and store.csv)3.Merging datasets and standardizing column names (e.g., to snake_case)4.Handling data types and filling missing values (NA) for competition and promotion fields555555555.STEP 02: Feature Engineering & HypothesesCreation of a Mind Map to list potential sales drivers (Customer, Store, Product, and Temporal factors)6.Development of key temporal features such as the duration of the competition (competition_time_month) and promotion (promo_time_week) in weeks/months7.Conversion of categorical features (assortment, state_holiday) to more descriptive labels8.STEP 03: FilteringRemoval of non-relevant data rows (stores that were closed and days with zero sales)9.Exclusion of unnecessary columns for modeling (e.g., customers, open, promo_interval, month_map)10.STEP 04: Exploratory Data Analysis (EDA)Univariate, bivariate, and multivariate analysis of variables11.Validation of Business Hypotheses (e.g., "Sales should be higher after the 10th of each month" - TRUE)12.STEP 05 - 09 (Inferred): Modeling and Feature SelectionData preparation for training (Categorical Encoding and Numerical Scaling using RobustScaler and MinMaxScaler)13.Feature Selection using the BorutaPy algorithm14.Model Training and Comparison (models included: LinearRegression, Lasso, RandomForestRegressor, and XGBoost as the top candidate)15.Temporal Cross-Validation was used to ensure the model's robustness over time16.STEP 10: DeploymentThe final model is serialized and deployed as an API for real-time inference (utilizing Flask)17.üßê Business Hypotheses Summary (EDA)The EDA phase focused on validating several hypotheses to understand how different factors influence sales, summarized by their impact relevance18:HypothesisConclusionRelevanceH11 (Sales after the 10th of the month)TRUE (Sales are higher) 19HighH12 (Sales on weekends)TRUE (Sales are lower) 20HighH9 (Sales over the years)FALSE (Sales decline over the years) 21HighH10 (Sales in the second half of the year)FALSE (Sales are lower) 22HighH2 (Stores with closer competitors sell less)FALSE (Stores with closer competitors sell more) 23MediumH3 (Stores with older competitors sell more)FALSE (Stores with older competitors sell less) 24MediumH8 (Stores open during Christmas holiday sell more)FALSE (Stores open during Christmas sell less) 25Mediumüõ†Ô∏è Technologies and LibrariesThe project was developed in Python, leveraging the following libraries:Language: PythonData Analysis: Pandas, Numpy26.Data Visualization: Matplotlib, Seaborn27.Machine Learning: XGBoost (key model), RandomForestRegressor, LinearRegression, Lasso28.Feature Selection: BorutaPy29.Preprocessing: Scikit-learn (RobustScaler, MinMaxScaler, LabelEncoder)30.Deployment/API (Inferred): Flask (for API) and a hosting service like Heroku (suggested by the test URL)31.üåê Deployment (API)The final prediction model is served via a REST API for straightforward consumption:ItemDetailPrediction Endpoint/rossmann/predictMethodPOSTExample URLhttps://rossmann-model-test.herokuapp.com/rossmann/predictInputJSON containing raw store data for prediction (18 columns)32.OutputJSON containing the predicted sales (exponentiated from log scale) for each store33.The core logic for deployment is likely encapsulated within a class named Rossmann, which manages the pre-processing pipeline and the model prediction34.üì¶ How to Install and RunClone the repository:Bashgit clone [your-repo-link]
cd rossmann-sales-prediction
Create and activate the virtual environment (e.g., using conda):Bashconda create -n rossmann python=3.9
conda activate rossmann
Install dependencies:Bashpip install -r requirements.txt
Run the notebook to reproduce the analysis:The analysis project is contained in the m10_v01_store_sales_prediction.pdf file (or its .ipynb format, if available).Run the API locally (for deployment):Bash# Assuming the API entry point is app.py
python app.py
The API should start at http://0.0.0.0:5000/.
